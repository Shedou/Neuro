usage: launch.py [-h] [--update-all-extensions] [--skip-python-version-check] [--skip-torch-cuda-test]
                 [--reinstall-xformers] [--reinstall-torch] [--update-check] [--test-server]
                 [--skip-prepare-environment] [--skip-install] [--data-dir DATA_DIR] [--config CONFIG] [--ckpt CKPT]
                 [--ckpt-dir CKPT_DIR] [--vae-dir VAE_DIR] [--gfpgan-dir GFPGAN_DIR] [--gfpgan-model GFPGAN_MODEL]
                 [--no-half] [--no-half-vae] [--no-progressbar-hiding] [--max-batch-count MAX_BATCH_COUNT]
                 [--embeddings-dir EMBEDDINGS_DIR] [--textual-inversion-templates-dir TEXTUAL_INVERSION_TEMPLATES_DIR]
                 [--hypernetwork-dir HYPERNETWORK_DIR] [--localizations-dir LOCALIZATIONS_DIR] [--allow-code]
                 [--medvram] [--lowvram] [--lowram] [--always-batch-cond-uncond] [--unload-gfpgan]
                 [--precision {full,autocast}] [--upcast-sampling] [--share] [--ngrok NGROK]
                 [--ngrok-region NGROK_REGION] [--ngrok-options NGROK_OPTIONS] [--enable-insecure-extension-access]
                 [--codeformer-models-path CODEFORMER_MODELS_PATH] [--gfpgan-models-path GFPGAN_MODELS_PATH]
                 [--esrgan-models-path ESRGAN_MODELS_PATH] [--bsrgan-models-path BSRGAN_MODELS_PATH]
                 [--realesrgan-models-path REALESRGAN_MODELS_PATH] [--clip-models-path CLIP_MODELS_PATH] [--xformers]
                 [--force-enable-xformers] [--xformers-flash-attention] [--deepdanbooru] [--opt-split-attention]
                 [--opt-sub-quad-attention] [--sub-quad-q-chunk-size SUB_QUAD_Q_CHUNK_SIZE]
                 [--sub-quad-kv-chunk-size SUB_QUAD_KV_CHUNK_SIZE]
                 [--sub-quad-chunk-threshold SUB_QUAD_CHUNK_THRESHOLD] [--opt-split-attention-invokeai]
                 [--opt-split-attention-v1] [--opt-sdp-attention] [--opt-sdp-no-mem-attention]
                 [--disable-opt-split-attention] [--disable-nan-check] [--use-cpu USE_CPU [USE_CPU ...]] [--listen]
                 [--port PORT] [--show-negative-prompt] [--ui-config-file UI_CONFIG_FILE] [--hide-ui-dir-config]
                 [--freeze-settings] [--ui-settings-file UI_SETTINGS_FILE] [--gradio-debug]
                 [--gradio-auth GRADIO_AUTH] [--gradio-auth-path GRADIO_AUTH_PATH]
                 [--gradio-img2img-tool GRADIO_IMG2IMG_TOOL] [--gradio-inpaint-tool GRADIO_INPAINT_TOOL]
                 [--gradio-allowed-path GRADIO_ALLOWED_PATH] [--opt-channelslast] [--styles-file STYLES_FILE]
                 [--autolaunch] [--theme THEME] [--use-textbox-seed] [--disable-console-progressbars]
                 [--enable-console-prompts] [--vae-path VAE_PATH] [--disable-safe-unpickle] [--api]
                 [--api-auth API_AUTH] [--api-log] [--nowebui] [--ui-debug-mode] [--device-id DEVICE_ID]
                 [--administrator] [--cors-allow-origins CORS_ALLOW_ORIGINS]
                 [--cors-allow-origins-regex CORS_ALLOW_ORIGINS_REGEX] [--tls-keyfile TLS_KEYFILE]
                 [--tls-certfile TLS_CERTFILE] [--disable-tls-verify] [--server-name SERVER_NAME] [--gradio-queue]
                 [--no-gradio-queue] [--skip-version-check] [--no-hashing] [--no-download-sd-model]
                 [--subpath SUBPATH] [--add-stop-route]

options:
  -h, --help            show this help message and exit
  --update-all-extensions
                        launch.py argument: download updates for all extensions when starting the program
  --skip-python-version-check
                        launch.py argument: do not check python version
  --skip-torch-cuda-test
                        launch.py argument: do not check if CUDA is able to work properly
  --reinstall-xformers  launch.py argument: install the appropriate version of xformers even if you have some version
                        already installed
  --reinstall-torch     launch.py argument: install the appropriate version of torch even if you have some version
                        already installed
  --update-check        launch.py argument: chck for updates at startup
  --test-server         launch.py argument: configure server for testing
  --skip-prepare-environment
                        launch.py argument: skip all environment preparation
  --skip-install        launch.py argument: skip installation of packages
  --data-dir DATA_DIR   base path where all user data is stored
  --config CONFIG       path to config which constructs model
  --ckpt CKPT           path to checkpoint of stable diffusion model; if specified, this checkpoint will be added to
                        the list of checkpoints and loaded
  --ckpt-dir CKPT_DIR   Path to directory with stable diffusion checkpoints
  --vae-dir VAE_DIR     Path to directory with VAE files
  --gfpgan-dir GFPGAN_DIR
                        GFPGAN directory
  --gfpgan-model GFPGAN_MODEL
                        GFPGAN model file name
  --no-half             do not switch the model to 16-bit floats
  --no-half-vae         do not switch the VAE model to 16-bit floats
  --no-progressbar-hiding
                        do not hide progressbar in gradio UI (we hide it because it slows down ML if you have hardware
                        acceleration in browser)
  --max-batch-count MAX_BATCH_COUNT
                        maximum batch count value for the UI
  --embeddings-dir EMBEDDINGS_DIR
                        embeddings directory for textual inversion (default: embeddings)
  --textual-inversion-templates-dir TEXTUAL_INVERSION_TEMPLATES_DIR
                        directory with textual inversion templates
  --hypernetwork-dir HYPERNETWORK_DIR
                        hypernetwork directory
  --localizations-dir LOCALIZATIONS_DIR
                        localizations directory
  --allow-code          allow custom script execution from webui
  --medvram             enable stable diffusion model optimizations for sacrificing a little speed for low VRM usage
  --lowvram             enable stable diffusion model optimizations for sacrificing a lot of speed for very low VRM
                        usage
  --lowram              load stable diffusion checkpoint weights to VRAM instead of RAM
  --always-batch-cond-uncond
                        disables cond/uncond batching that is enabled to save memory with --medvram or --lowvram
  --unload-gfpgan       does not do anything.
  --precision {full,autocast}
                        evaluate at this precision
  --upcast-sampling     upcast sampling. No effect with --no-half. Usually produces similar results to --no-half with
                        better performance while using less memory.
  --share               use share=True for gradio and make the UI accessible through their site
  --ngrok NGROK         ngrok authtoken, alternative to gradio --share
  --ngrok-region NGROK_REGION
                        does not do anything.
  --ngrok-options NGROK_OPTIONS
                        The options to pass to ngrok in JSON format, e.g.: '{"authtoken_from_env":true,
                        "basic_auth":"user:password", "oauth_provider":"google",
                        "oauth_allow_emails":"user@asdf.com"}'
  --enable-insecure-extension-access
                        enable extensions tab regardless of other options
  --codeformer-models-path CODEFORMER_MODELS_PATH
                        Path to directory with codeformer model file(s).
  --gfpgan-models-path GFPGAN_MODELS_PATH
                        Path to directory with GFPGAN model file(s).
  --esrgan-models-path ESRGAN_MODELS_PATH
                        Path to directory with ESRGAN model file(s).
  --bsrgan-models-path BSRGAN_MODELS_PATH
                        Path to directory with BSRGAN model file(s).
  --realesrgan-models-path REALESRGAN_MODELS_PATH
                        Path to directory with RealESRGAN model file(s).
  --clip-models-path CLIP_MODELS_PATH
                        Path to directory with CLIP model file(s).
  --xformers            enable xformers for cross attention layers
  --force-enable-xformers
                        enable xformers for cross attention layers regardless of whether the checking code thinks you
                        can run it; do not make bug reports if this fails to work
  --xformers-flash-attention
                        enable xformers with Flash Attention to improve reproducibility (supported for SD2.x or
                        variant only)
  --deepdanbooru        does not do anything
  --opt-split-attention
                        prefer Doggettx's cross-attention layer optimization for automatic choice of optimization
  --opt-sub-quad-attention
                        prefer memory efficient sub-quadratic cross-attention layer optimization for automatic choice
                        of optimization
  --sub-quad-q-chunk-size SUB_QUAD_Q_CHUNK_SIZE
                        query chunk size for the sub-quadratic cross-attention layer optimization to use
  --sub-quad-kv-chunk-size SUB_QUAD_KV_CHUNK_SIZE
                        kv chunk size for the sub-quadratic cross-attention layer optimization to use
  --sub-quad-chunk-threshold SUB_QUAD_CHUNK_THRESHOLD
                        the percentage of VRAM threshold for the sub-quadratic cross-attention layer optimization to
                        use chunking
  --opt-split-attention-invokeai
                        prefer InvokeAI's cross-attention layer optimization for automatic choice of optimization
  --opt-split-attention-v1
                        prefer older version of split attention optimization for automatic choice of optimization
  --opt-sdp-attention   prefer scaled dot product cross-attention layer optimization for automatic choice of
                        optimization; requires PyTorch 2.*
  --opt-sdp-no-mem-attention
                        prefer scaled dot product cross-attention layer optimization without memory efficient
                        attention for automatic choice of optimization, makes image generation deterministic; requires
                        PyTorch 2.*
  --disable-opt-split-attention
                        prefer no cross-attention layer optimization for automatic choice of optimization
  --disable-nan-check   do not check if produced images/latent spaces have nans; useful for running without a
                        checkpoint in CI
  --use-cpu USE_CPU [USE_CPU ...]
                        use CPU as torch device for specified modules
  --listen              launch gradio with 0.0.0.0 as server name, allowing to respond to network requests
  --port PORT           launch gradio with given server port, you need root/admin rights for ports < 1024, defaults to
                        7860 if available
  --show-negative-prompt
                        does not do anything
  --ui-config-file UI_CONFIG_FILE
                        filename to use for ui configuration
  --hide-ui-dir-config  hide directory configuration from webui
  --freeze-settings     disable editing settings
  --ui-settings-file UI_SETTINGS_FILE
                        filename to use for ui settings
  --gradio-debug        launch gradio with --debug option
  --gradio-auth GRADIO_AUTH
                        set gradio authentication like "username:password"; or comma-delimit multiple like
                        "u1:p1,u2:p2,u3:p3"
  --gradio-auth-path GRADIO_AUTH_PATH
                        set gradio authentication file path ex. "/path/to/auth/file" same auth format as --gradio-auth
  --gradio-img2img-tool GRADIO_IMG2IMG_TOOL
                        does not do anything
  --gradio-inpaint-tool GRADIO_INPAINT_TOOL
                        does not do anything
  --gradio-allowed-path GRADIO_ALLOWED_PATH
                        add path to gradio's allowed_paths, make it possible to serve files from it
  --opt-channelslast    change memory type for stable diffusion to channels last
  --styles-file STYLES_FILE
                        filename to use for styles
  --autolaunch          open the webui URL in the system's default browser upon launch
  --theme THEME         launches the UI with light or dark theme
  --use-textbox-seed    use textbox for seeds in UI (no up/down, but possible to input long seeds)
  --disable-console-progressbars
                        do not output progressbars to console
  --enable-console-prompts
                        print prompts to console when generating with txt2img and img2img
  --vae-path VAE_PATH   Checkpoint to use as VAE; setting this argument disables all settings related to VAE
  --disable-safe-unpickle
                        disable checking pytorch models for malicious code
  --api                 use api=True to launch the API together with the webui (use --nowebui instead for only the
                        API)
  --api-auth API_AUTH   Set authentication for API like "username:password"; or comma-delimit multiple like
                        "u1:p1,u2:p2,u3:p3"
  --api-log             use api-log=True to enable logging of all API requests
  --nowebui             use api=True to launch the API instead of the webui
  --ui-debug-mode       Don't load model to quickly launch UI
  --device-id DEVICE_ID
                        Select the default CUDA device to use (export CUDA_VISIBLE_DEVICES=0,1,etc might be needed
                        before)
  --administrator       Administrator rights
  --cors-allow-origins CORS_ALLOW_ORIGINS
                        Allowed CORS origin(s) in the form of a comma-separated list (no spaces)
  --cors-allow-origins-regex CORS_ALLOW_ORIGINS_REGEX
                        Allowed CORS origin(s) in the form of a single regular expression
  --tls-keyfile TLS_KEYFILE
                        Partially enables TLS, requires --tls-certfile to fully function
  --tls-certfile TLS_CERTFILE
                        Partially enables TLS, requires --tls-keyfile to fully function
  --disable-tls-verify  When passed, enables the use of self-signed certificates.
  --server-name SERVER_NAME
                        Sets hostname of server
  --gradio-queue        does not do anything
  --no-gradio-queue     Disables gradio queue; causes the webpage to use http requests instead of websockets; was the
                        defaul in earlier versions
  --skip-version-check  Do not check versions of torch and xformers
  --no-hashing          disable sha256 hashing of checkpoints to help loading performance
  --no-download-sd-model
                        don't download SD1.5 model even if no model is found in --ckpt-dir
  --subpath SUBPATH     customize the subpath for gradio, use with reverse proxy
  --add-stop-route      add /_stop route to stop server